### Today’s freaky [LLM behavior](https://alignment.anthropic.com/2025/subliminal-learning/):

* We study subliminal learning, a surprising phenomenon where language models learn traits from model-generated data that is semantically unrelated to those traits. For example, a “student” model learns to prefer owls when trained on sequences of numbers generated by a “teacher” model that prefers owls. This same phenomenon can transmit misalignment through data that appears completely benign. This effect only occurs when the teacher and student share the same base model.
  * Interesting security implications.
  * I am more convinced than ever that we need serious research into [AI integrity](https://www.schneier.com/essays/archives/2025/06/the-age-of-integrity.html) 
if we are ever going to have [trustworthy AI](https://www.schneier.com/essays/archives/2025/06/ai-and-trust-2.html).